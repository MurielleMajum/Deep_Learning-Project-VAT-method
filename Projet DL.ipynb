{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45319,"status":"ok","timestamp":1704892037603,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"ODI3fgdr0Kt_","outputId":"9f1aba23-a4cc-40ca-f0f5-8665a47115f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2THr1uc0ha_"},"outputs":[],"source":["import requests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bio6F8-R0hdo"},"outputs":[],"source":["url_train_image = \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\"\n","train_image = \"train-images-idx3-ubyte.gz\"\n","# Téléchargez le fichier depuis le lien\n","response = requests.get(url_train_image)\n","with open(train_image, 'wb') as file:\n","    file.write(response.content)\n","\n","url_train_label = \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\"\n","train_label = \"train-labels-idx1-ubyte.gz\"\n","# Téléchargez le fichier depuis le lien\n","response = requests.get(url_train_label)\n","with open(train_label, 'wb') as file:\n","    file.write(response.content)\n","\n","url_test_image = \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\"\n","test_image = \"t10k-images-idx3-ubyte.gz\"\n","# Téléchargez le fichier depuis le lien\n","response = requests.get(url_test_image)\n","with open(test_image, 'wb') as file:\n","    file.write(response.content)\n","\n","url_test_label = \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"\n","test_label = \"t10k-labels-idx1-ubyte.gz\"\n","# Téléchargez le fichier depuis le lien\n","response = requests.get(url_test_label)\n","with open(test_label, 'wb') as file:\n","    file.write(response.content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0x3HRurF3Kl8"},"outputs":[],"source":["import gzip\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1704495317984,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"EZGsnPwj0hgQ","outputId":"4cb25a00-b9d6-4836-9961-f856340af9de"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(60000, 28, 28)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Décompressez le fichier .gz et chargez les données\n","with gzip.open(train_image, 'rb') as file:\n","    binary_train_image = file.read()\n","\n","# Les données MNIST commencent après les 16 premiers octets d'en-tête\n","# Le format MNIST est bien documenté, mais vous devrez peut-être ajuster\n","# ces valeurs en fonction du contenu spécifique du fichier\n","data_train_image = np.frombuffer(binary_train_image[16:], dtype=np.uint8)\n","data_train_image = data_train_image.reshape(-1, 28, 28)  # Les images MNIST sont de taille 28x28 pixels\n","\n","# Affichez une image MNIST (par exemple, la première image)\n","plt.imshow(data_train_image[2], cmap='gray')\n","plt.axis('off')\n","plt.show()\n","\n","data_train_image.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1704892050276,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"V9LPGfXr0hkD","outputId":"75439cc5-5cb3-442b-a558-7c4b1c874d14"},"outputs":[{"name":"stdout","output_type":"stream","text":["Étiquette de l'exemple 2: 4\n"]},{"data":{"text/plain":["(60000,)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Charger les données d'étiquettes\n","with gzip.open(train_label, 'rb') as file:\n","    binary_train_label = file.read()\n","# Les données d'étiquettes MNIST commencent après les 8 premiers octets d'en-tête\n","train_labels = np.frombuffer(binary_train_label[8:], dtype=np.uint8)\n","index = 2  # Remplacez par l'indice de l'exemple que vous souhaitez afficher\n","print(f\"Étiquette de l'exemple {index}: {train_labels[index]}\")\n","train_labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":594,"status":"ok","timestamp":1704892053053,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"8Og1_Mu-8TyV","outputId":"3043f77d-68af-45c6-efb8-827e30a5c432"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["with gzip.open(test_image, 'rb') as file:\n","    binary_test_image = file.read()\n","data_test_image = np.frombuffer(binary_test_image[16:], dtype=np.uint8)\n","data_test_image = data_test_image.reshape(-1, 28, 28)\n","plt.imshow(data_test_image[2], cmap='gray')\n","plt.axis('off')\n","plt.show()\n","data_test_image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1704892057785,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"6XUATkYL8UAr","outputId":"d74b0f7e-ffc5-4e7d-c2c2-9b3b3d359212"},"outputs":[{"name":"stdout","output_type":"stream","text":["Étiquette de l'exemple 2: 1\n"]}],"source":["# Charger les données d'étiquettes\n","with gzip.open(test_label, 'rb') as file:\n","    binary_test_label = file.read()\n","# Les données d'étiquettes MNIST commencent après les 8 premiers octets d'en-tête\n","test_labels = np.frombuffer(binary_test_label[8:], dtype=np.uint8)\n","index = 2  # Remplacez par l'indice de l'exemple que vous souhaitez afficher\n","print(f\"Étiquette de l'exemple {index}: {test_labels[index]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8603,"status":"ok","timestamp":1704892067816,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"zHVq0jkd8UC6","outputId":"7a8b02fd-6162-4156-f979-b2db215248d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 104424329.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 31204454.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 32917298.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 16076395.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]}],"source":["import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Définir la transformation pour normaliser les images\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","# Télécharger le jeu de données MNIST\n","train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n","\n","# Créer des chargeurs de données pour l'entraînement et les tests\n","train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"-O467qRmglwc"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0yKCt0Igv4W"},"outputs":[],"source":["# Ce code utilise un réseau de neurones convolutif simple avec deux couches de convolution suivies de couches de ReLU et de pooling, puis deux\n","# couches entièrement connectées. Il entraîne le modèle sur l'ensemble d'entraînement MNIST pendant un certain nombre d'époques et évalue la\n","# précision du modèle sur l'ensemble de test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJ-RML46fuc1"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LVXvgUMS8UG6"},"outputs":[],"source":["# Définir l'architecture du réseau de neurones convolutif (CNN)\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","        x = x.view(-1, 64 * 7 * 7)\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"-lP-OXuhja-u","outputId":"a8b58c7e-cca5-424e-d620-e6f0518972a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Batch 0/938, Loss: 2.3023040294647217\n","Epoch 1/5, Batch 100/938, Loss: 0.22820913791656494\n","Epoch 1/5, Batch 200/938, Loss: 0.2580619752407074\n","Epoch 1/5, Batch 300/938, Loss: 0.10118012875318527\n","Epoch 1/5, Batch 400/938, Loss: 0.09285466372966766\n","Epoch 1/5, Batch 500/938, Loss: 0.07604522258043289\n","Epoch 1/5, Batch 600/938, Loss: 0.0333879180252552\n","Epoch 1/5, Batch 700/938, Loss: 0.0854552611708641\n","Epoch 1/5, Batch 800/938, Loss: 0.02179553173482418\n","Epoch 1/5, Batch 900/938, Loss: 0.049387913197278976\n","Epoch 2/5, Batch 0/938, Loss: 0.059390727430582047\n","Epoch 2/5, Batch 100/938, Loss: 0.013276943005621433\n","Epoch 2/5, Batch 200/938, Loss: 0.044115107506513596\n","Epoch 2/5, Batch 300/938, Loss: 0.07214052230119705\n","Epoch 2/5, Batch 400/938, Loss: 0.13999582827091217\n","Epoch 2/5, Batch 500/938, Loss: 0.044288020581007004\n","Epoch 2/5, Batch 600/938, Loss: 0.006095689255744219\n","Epoch 2/5, Batch 700/938, Loss: 0.06374522298574448\n","Epoch 2/5, Batch 800/938, Loss: 0.10705223679542542\n","Epoch 2/5, Batch 900/938, Loss: 0.005668903235346079\n","Epoch 3/5, Batch 0/938, Loss: 0.054577481001615524\n","Epoch 3/5, Batch 100/938, Loss: 0.02422335557639599\n","Epoch 3/5, Batch 200/938, Loss: 0.04515954479575157\n","Epoch 3/5, Batch 300/938, Loss: 0.015000278130173683\n","Epoch 3/5, Batch 400/938, Loss: 0.0027320650406181812\n","Epoch 3/5, Batch 500/938, Loss: 0.014008775353431702\n","Epoch 3/5, Batch 600/938, Loss: 0.0010650190524756908\n","Epoch 3/5, Batch 700/938, Loss: 0.017156342044472694\n","Epoch 3/5, Batch 800/938, Loss: 0.02005392126739025\n","Epoch 3/5, Batch 900/938, Loss: 0.003228246932849288\n","Epoch 4/5, Batch 0/938, Loss: 0.026426980271935463\n","Epoch 4/5, Batch 100/938, Loss: 0.04693661257624626\n","Epoch 4/5, Batch 200/938, Loss: 0.10182251036167145\n","Epoch 4/5, Batch 300/938, Loss: 0.0025651357136666775\n","Epoch 4/5, Batch 400/938, Loss: 0.0017193914391100407\n","Epoch 4/5, Batch 500/938, Loss: 0.006842600181698799\n","Epoch 4/5, Batch 600/938, Loss: 0.08260446041822433\n","Epoch 4/5, Batch 700/938, Loss: 0.0023078336380422115\n","Epoch 4/5, Batch 800/938, Loss: 0.008323796093463898\n","Epoch 4/5, Batch 900/938, Loss: 0.002476218156516552\n","Epoch 5/5, Batch 0/938, Loss: 0.015571929514408112\n","Epoch 5/5, Batch 100/938, Loss: 0.004563783295452595\n","Epoch 5/5, Batch 200/938, Loss: 0.008312973193824291\n","Epoch 5/5, Batch 300/938, Loss: 0.007136168424040079\n","Epoch 5/5, Batch 400/938, Loss: 0.00534712802618742\n","Epoch 5/5, Batch 500/938, Loss: 0.00029663954046554863\n","Epoch 5/5, Batch 600/938, Loss: 0.0002971792418975383\n","Epoch 5/5, Batch 700/938, Loss: 0.000309978291625157\n","Epoch 5/5, Batch 800/938, Loss: 0.034601010382175446\n","Epoch 5/5, Batch 900/938, Loss: 0.008192760869860649\n","Accuracy on the test set: 99.10%\n"]}],"source":["# Instancier le modèle, la fonction de coût et l'optimiseur\n","model = CNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Entraînement du modèle\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n","\n","# Évaluation du modèle sur l'ensemble de test\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        output = model(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","accuracy = correct / total\n","print(f'Accuracy on the test set: {100 * accuracy:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SXC9RXh8UK7"},"outputs":[],"source":["## Algorithme 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1704495739928,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"BiSmUfga8UM7","outputId":"8be32dfd-0a87-43ee-cf52-24536a3a548c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# Définir le nombre d\\'échantillons et la dimensionnalité du vecteur aléatoire\\n# M = 32  # Vous pouvez ajuster cette valeur en fonction de votre jeu de données\\n# I = 28 * 28  # La dimensionnalité de l\\'image MNIST\\n\\n# # Nombre d\\'itérations de puissance\\n# K = 1\\n\\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n\\n# # Boucle d\\'entraînement\\n# num_epochs = 3  # Vous pouvez ajuster le nombre d\\'époques\\n# for epoch in range(num_epochs):\\n#     for batch_idx, (data, target) in enumerate(train_loader):\\n#         # Étape 1: Choisir M échantillons de x à partir du jeu de données\\n#         data, target = data.to(device), target.to(device)\\n\\n#         # Étape 2: Générer un vecteur aléatoire d pour chaque échantillon\\n#         d = torch.randn(M, I).to(device)\\n#         #d = torch.randn(data.size(0), I).to(device)\\n#         d /= torch.norm(d, dim=1, keepdim=True)\\n\\n#         # Répéter d pour avoir la même taille de batch que les données\\n#         d = d.repeat(data.size(0), 1)\\n\\n#         # Étape 3: Calculer r_vadv pour chaque échantillon\\n#         r_vadv = torch.zeros_like(d).to(device)\\n\\n#         for k in range(K):\\n#             # Calculer le gradient du modèle par rapport à l\\'entrée\\n#             data.requires_grad = True\\n#             output = model(data)\\n#             loss = criterion(output, target)\\n#             grad = torch.autograd.grad(loss, data, create_graph=True)[0]\\n\\n#             # Calculer r_vadv en utilisant l\\'itération de puissance\\n#             grad_flat = grad.view(grad.size(0), 1, -1)\\n#             d_expanded = d.view(d.size(0), 1, -1)\\n#             r_vadv += torch.bmm(grad_flat, d_expanded).squeeze()\\n\\n#             # Mettre à jour les données d\\'entrée en utilisant r_vadv calculé\\n#             data = data + 0.5 * r_vadv\\n\\n#         r_vadv /= K\\n#         r_vadv /= torch.norm(r_vadv, dim=1, keepdim=True)\\n\\n#         # Étape 4: Retourner le gradient par rapport aux paramètres du modèle\\n#         optimizer.zero_grad()\\n#         output = model(data)\\n#         loss = criterion(output, target)\\n#         loss.backward()\\n#         optimizer.step()\\n\\n#         if batch_idx % 100 == 0:\\n#             print(f\\'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\\')\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","\"\"\"\n","# Définir le nombre d'échantillons et la dimensionnalité du vecteur aléatoire\n","# M = 32  # Vous pouvez ajuster cette valeur en fonction de votre jeu de données\n","# I = 28 * 28  # La dimensionnalité de l'image MNIST\n","\n","# # Nombre d'itérations de puissance\n","# K = 1\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # Boucle d'entraînement\n","# num_epochs = 3  # Vous pouvez ajuster le nombre d'époques\n","# for epoch in range(num_epochs):\n","#     for batch_idx, (data, target) in enumerate(train_loader):\n","#         # Étape 1: Choisir M échantillons de x à partir du jeu de données\n","#         data, target = data.to(device), target.to(device)\n","\n","#         # Étape 2: Générer un vecteur aléatoire d pour chaque échantillon\n","#         d = torch.randn(M, I).to(device)\n","#         #d = torch.randn(data.size(0), I).to(device)\n","#         d /= torch.norm(d, dim=1, keepdim=True)\n","\n","#         # Répéter d pour avoir la même taille de batch que les données\n","#         d = d.repeat(data.size(0), 1)\n","\n","#         # Étape 3: Calculer r_vadv pour chaque échantillon\n","#         r_vadv = torch.zeros_like(d).to(device)\n","\n","#         for k in range(K):\n","#             # Calculer le gradient du modèle par rapport à l'entrée\n","#             data.requires_grad = True\n","#             output = model(data)\n","#             loss = criterion(output, target)\n","#             grad = torch.autograd.grad(loss, data, create_graph=True)[0]\n","\n","#             # Calculer r_vadv en utilisant l'itération de puissance\n","#             grad_flat = grad.view(grad.size(0), 1, -1)\n","#             d_expanded = d.view(d.size(0), 1, -1)\n","#             r_vadv += torch.bmm(grad_flat, d_expanded).squeeze()\n","\n","#             # Mettre à jour les données d'entrée en utilisant r_vadv calculé\n","#             data = data + 0.5 * r_vadv\n","\n","#         r_vadv /= K\n","#         r_vadv /= torch.norm(r_vadv, dim=1, keepdim=True)\n","\n","#         # Étape 4: Retourner le gradient par rapport aux paramètres du modèle\n","#         optimizer.zero_grad()\n","#         output = model(data)\n","#         loss = criterion(output, target)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         if batch_idx % 100 == 0:\n","#             print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1704495739928,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"EYmhlQUN8UQC","outputId":"5e93bacb-ce53-4d50-feb6-bc69cb42a1f8"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# Boucle d'entraînement\\nnum_epochs = 5  # Vous pouvez ajuster le nombre d'époques\\nfor epoch in range(num_epochs):\\n    for batch_idx, (data, target) in enumerate(train_loader):\\n        # Étape 1: Choisir M échantillons de x à partir du jeu de données\\n        data, target = data.to(device), target.to(device)\\n\\n        # Étape 2: Générer un vecteur aléatoire d pour chaque échantillon\\n        d = torch.randn(data.size(0), I).to(device)\\n        d /= torch.norm(d, dim=1, keepdim=True)\\n\\n        # Étape 3: Calculer r_vadv pour chaque échantillon\\n        r_vadv = torch.zeros_like(data).to(device)\\n\\n        for k in range(K):\\n            # Calculer le gradient du modèle par rapport à l'entrée\\n            data.requires_grad = True\\n            output = model(data)\\n            loss = criterion(output, target)\\n            grad = torch.autograd.grad(loss, data, create_graph=True)[0]\\n\\n            # Calculer r_vadv en utilisant l'itération de puissance\\n            r_vadv += grad * d.view(-1, 1, I)\\n\\n            # Mettre à jour les données d'entrée en utilisant r_vadv calculé\\n            data = data + 0.5 * r_vadv\\n\\n        r_vadv /= K\\n        r_vadv /= torch.norm(r_vadv, dim=1, keepdim=True)\\n\\n        # Étape 4: Retourner le gradient par rapport aux paramètres du modèle\\n        optimizer.zero_grad()\\n        output = model(data)\\n        loss = criterion(output, target)\\n        loss.backward()\\n        optimizer.step()\\n\\n        if batch_idx % 100 == 0:\\n            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\\n\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","# Boucle d'entraînement\n","num_epochs = 5  # Vous pouvez ajuster le nombre d'époques\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Étape 1: Choisir M échantillons de x à partir du jeu de données\n","        data, target = data.to(device), target.to(device)\n","\n","        # Étape 2: Générer un vecteur aléatoire d pour chaque échantillon\n","        d = torch.randn(data.size(0), I).to(device)\n","        d /= torch.norm(d, dim=1, keepdim=True)\n","\n","        # Étape 3: Calculer r_vadv pour chaque échantillon\n","        r_vadv = torch.zeros_like(data).to(device)\n","\n","        for k in range(K):\n","            # Calculer le gradient du modèle par rapport à l'entrée\n","            data.requires_grad = True\n","            output = model(data)\n","            loss = criterion(output, target)\n","            grad = torch.autograd.grad(loss, data, create_graph=True)[0]\n","\n","            # Calculer r_vadv en utilisant l'itération de puissance\n","            r_vadv += grad * d.view(-1, 1, I)\n","\n","            # Mettre à jour les données d'entrée en utilisant r_vadv calculé\n","            data = data + 0.5 * r_vadv\n","\n","        r_vadv /= K\n","        r_vadv /= torch.norm(r_vadv, dim=1, keepdim=True)\n","\n","        # Étape 4: Retourner le gradient par rapport aux paramètres du modèle\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSK2d4gipCKN","outputId":"34b2ff33-018a-43a8-88dc-39cf71d0ef68"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Batch 0/938, Loss: 0.0009551274706609547\n","Epoch 1/3, Batch 100/938, Loss: 0.0012912238016724586\n","Epoch 1/3, Batch 200/938, Loss: 0.00314608053304255\n","Epoch 1/3, Batch 300/938, Loss: 0.03905627131462097\n","Epoch 1/3, Batch 400/938, Loss: 0.001368371187709272\n","Epoch 1/3, Batch 500/938, Loss: 0.006273564882576466\n","Epoch 1/3, Batch 600/938, Loss: 0.000697897223290056\n","Epoch 1/3, Batch 700/938, Loss: 0.01711876131594181\n","Epoch 1/3, Batch 800/938, Loss: 0.03940041735768318\n","Epoch 1/3, Batch 900/938, Loss: 0.0012003128649666905\n","Epoch 2/3, Batch 0/938, Loss: 0.005484995432198048\n","Epoch 2/3, Batch 100/938, Loss: 0.00038354829302988946\n","Epoch 2/3, Batch 200/938, Loss: 0.00021043172455392778\n","Epoch 2/3, Batch 300/938, Loss: 0.009570302441716194\n","Epoch 2/3, Batch 400/938, Loss: 0.0032887968700379133\n","Epoch 2/3, Batch 500/938, Loss: 0.02478928677737713\n","Epoch 2/3, Batch 600/938, Loss: 0.0009871518705040216\n","Epoch 2/3, Batch 700/938, Loss: 0.01428748294711113\n","Epoch 2/3, Batch 800/938, Loss: 0.005512699484825134\n","Epoch 2/3, Batch 900/938, Loss: 0.02620578557252884\n","Epoch 3/3, Batch 0/938, Loss: 0.000987403211183846\n","Epoch 3/3, Batch 100/938, Loss: 0.002820305759087205\n","Epoch 3/3, Batch 200/938, Loss: 0.004680747631937265\n","Epoch 3/3, Batch 300/938, Loss: 0.0020045130513608456\n","Epoch 3/3, Batch 400/938, Loss: 0.0022443709895014763\n","Epoch 3/3, Batch 500/938, Loss: 0.0194983072578907\n","Epoch 3/3, Batch 600/938, Loss: 0.0004113280156161636\n","Epoch 3/3, Batch 700/938, Loss: 0.00287693552672863\n","Epoch 3/3, Batch 800/938, Loss: 0.00014632275269832462\n","Epoch 3/3, Batch 900/938, Loss: 0.00027535256231203675\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#Définir le nombre d'échantillons et la dimensionnalité du vecteur aléatoire\n","M = 32  # Vous pouvez ajuster cette valeur en fonction de votre jeu de données\n","I = 28 * 28  # La dimensionnalité de l'image MNIST\n","\n","# # Nombre d'itérations de puissance\n","K = 1\n","# Boucle d'entraînement\n","num_epochs = 3  # Vous pouvez ajuster le nombre d'époques\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Étape 1: Choisir M échantillons de x à partir du jeu de données\n","        data, target = data.to(device), target.to(device)\n","\n","        # Étape 2: Générer un vecteur aléatoire d pour chaque échantillon\n","        d = torch.randn(data.size(0), 1, 28, 28).to(device)  # Ajuster la taille pour MNIST\n","        d /= torch.norm(d, dim=(2, 3), keepdim=True)\n","\n","        # Étape 3: Calculer r_vadv pour chaque échantillon\n","        r_vadv = torch.zeros_like(data).to(device)\n","\n","        for k in range(K):\n","            # Calculer le gradient du modèle par rapport à l'entrée\n","            data.requires_grad = True\n","            output = model(data)\n","            loss = criterion(output, target)\n","            grad = torch.autograd.grad(loss, data, create_graph=True)[0]\n","\n","            # Calculer r_vadv en utilisant l'itération de puissance\n","            r_vadv += grad * d\n","\n","            # Mettre à jour les données d'entrée en utilisant r_vadv calculé\n","            data = data + 0.5 * r_vadv\n","\n","        r_vadv /= K\n","        r_vadv /= torch.norm(r_vadv, dim=(2, 3), keepdim=True)\n","\n","        # Étape 4: Retourner le gradient par rapport aux paramètres du modèle\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"elapsed":1220,"status":"error","timestamp":1704500055679,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"},"user_tz":-60},"id":"YSUMJ31gtBqG","outputId":"c7a6a6ee-3fa7-4e8a-8c57-b5a68fb89c1d"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-97bce029570b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Évaluation du modèle sur l'ensemble de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["# Évaluation du modèle sur l'ensemble de test\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        output = model(data)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","accuracy = correct / total\n","print(f'Accuracy on the test set: {100 * accuracy:.2f}%')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FliBztsSteCx"},"outputs":[],"source":["###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7hwmB0fteRF","executionInfo":{"status":"ok","timestamp":1717957677224,"user_tz":-120,"elapsed":6,"user":{"displayName":"Murielle Majum","userId":"01195628224188037605"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wlaep_XgteTc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zMsGpTmwteWL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HStw5zbfteY0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPQF3Yw5tecF"},"outputs":[],"source":[]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}